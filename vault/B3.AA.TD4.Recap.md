---
id: tq1n4g1yvi31cirvtnerzn4
title: Recap
desc: ''
updated: 1676278304057
created: 1676271119030
---

> **Avertissement:**
Cette page peut contenir des fautes ! Envoyez-moi un message sur [`#UT3-AURO-M2-2223-Request:matrix.org`](https://matrix.to/#/#UT3-AURO-M2-2223-Request:matrix.org) si vous en trouvez, merci.

> Cours donné par P. Muller, T. Pellegrini

---

> Notes RKA du 2023/02/13 - Start




# Exercice 1: étapes d'apprentissage

![](/assets/images/B3.AA.TD4.Recap.Sujet-Ex01.png)

- Epochs = on a vu toute les batch au moins une fois
- Pour eviter de surapprendre on va aussi mesurer la validation sans la mettre a jour
- Surapprentissage = model n'arrive plus a predire des objets generaux car trop different de ce qu'il apprit par coeur
- Exemple typique: un étudiant qui apprend par coeur ces exos de TD et n'arrive pas à faire l'examen car le sujet est trop différent de celui du TD
- Earlystopping = si validation ne diminue plus on va arreter l'apprentissage
- Dropout =
- Pour une classification, la loss diminue mais pas l'accurancy (nb error/nb prediction) pourquoi ?
    - Souvent dans les classifications (surtout les binaires) on va être intéressé par d'identifier une seule classe
    - Precision "malade" = Nb Correct / Nb Predic
    - Rappel "malade" = Nb Correct / il fallait predire
    - Cross Entropy = evalue aussi sa confiance en ses resultat donc la loss diminue car il gagne en confiance mais cela ne change pas ses décisions donc son acc ne change plus

    ![](/assets/images/B3.AA.TD4.Recap.BB20230213-01.png)
    ![](/assets/images/B3.AA.TD4.Recap.BB20230213-02.png)
- Data Loarders = charger les données et les adaptés au réseau si besoin
- Init Model = Donne les composants du reseau
- Puis on ajoute dans le code un forward pour structurer le model en expliquant où appliquer les filtres et quelle fonction d'activation
    ![](/assets/images/B3.AA.TD4.Recap.BB20230213-03.png)
- Fuite de données
    ![](/assets/images/B3.AA.TD4.Recap.BB20230213-04.png)



# Exercice 2: 

![](/assets/images/B3.AA.TD4.Recap.Sujet-Ex02.png)

- Classification d'un article de journal sur sa position politique
    - Il faut des étiquettes et définir les catégories
    - On définit un RNN (car c'est le seul qui n'a pas d'entrée fixe donc adapté aux articles de taille variable)
        - On fait du one-hot encoding pour chaque mot (eviter le soucis de donner un poids et donc devoir specifier un ordre dans le lexique)
        - On applique ensuite un [[LSTM|B3.AA.CM.RNN#long-short-term-memory-networks-lstms]]
        ![](/assets/images/B3.AA.TD4.Recap.BB20230213-05.png)



- Détection de nodules
    - CNN en 3D donc les filtres seront aussi 
    - mais il risque d'avoir des problèmes de métriques (un oiseau chante vs il y a un oiseau) [problème de référence multiple]
    ![](/assets/images/B3.AA.TD4.Recap.BB20230213-06.png)



- Audio-Captioning
    - encodeur/decodeur avec une sortie différente de l'entrée (many-to-many)



- Question/Réponse:
    - [[LSTM|B3.AA.CM.RNN#long-short-term-memory-networks-lstms]] on peut implémenter un encodeur et un decodeur avec un sortie de meme taille que l'entrée
    - Comment collecter/constituer les données pour ce problème ?
        - On lui donne la réponse à l'agent de choisir la question
        - On a une doc contenant les réponses il ne reste plus qu'à avoir les questions
        - On peut générer des questions ou bien récupérer des questions déjà enregistrer par le passé



# Exercice 3:

![](/assets/images/B3.AA.TD4.Recap.Sujet-Ex03-01.png)
![](/assets/images/B3.AA.TD4.Recap.Sujet-Ex03-02.png)

![](/assets/images/B3.AA.TD4.Recap.BB20230213-07.png)

Biais de la bouge : si sourire probabilité forte de ne pas etre criminel



> Notes RKA du 2023/02/13 - End

---